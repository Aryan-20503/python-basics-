{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 1 : What is Simple Linear Regression (SLR)? Explain its purpose.**\n",
        "\n",
        "Definition\n",
        "\n",
        "Simple Linear Regression attempts to predict the value of Y (dependent variable) based on X (independent variable) using a linear equation of the form:\n",
        "\n",
        "            Y=Î²0â€‹+Î²1â€‹X+Îµ\n",
        "\n",
        "Where:\n",
        "\n",
        "- Y = Dependent (response) variable\n",
        "\n",
        "- X = Independent (predictor) variable\n",
        "\n",
        "- Î²â‚€ = Intercept (value of Y when X = 0)\n",
        "\n",
        "- Î²â‚ = Slope (change in Y for one unit change in X)\n",
        "\n",
        "- Îµ = Error term (difference between actual and predicted values)\n",
        "\n",
        "Purpose of Simple Linear Regression\n",
        "\n",
        "1. Prediction:\n",
        "To predict the value of the dependent variable based on a known value of the independent variable.\n",
        "Example: Predicting a studentâ€™s marks based on study hours.\n",
        "\n",
        "2. Relationship Analysis:\n",
        "To determine the strength and direction of the relationship between two variables.\n",
        "\n",
        "3. Positive slope â†’ as X increases, Y increases\n",
        "\n",
        "4. Negative slope â†’ as X increases, Y decreases\n",
        "\n",
        "5. Trend Identification:\n",
        "To identify and quantify trends in data (e.g., sales growth over time).\n",
        "\n",
        "6. Causal Insights (with caution):\n",
        "It can help suggest possible cause-and-effect relationships, though correlation doesnâ€™t always imply causation.\n",
        "\n"
      ],
      "metadata": {
        "id": "DhSP3LUQAxZ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2: What are the key assumptions of Simple Linear Regression?**\n",
        "\n",
        "The Simple Linear Regression (SLR) model is based on several key statistical assumptions that ensure the reliability and validity of the modelâ€™s estimates and predictions. Violating these assumptions can lead to biased, inefficient, or misleading results.\n",
        "\n",
        "Key Assumptions of Simple Linear Regression\n",
        "1. Linearity\n",
        "\n",
        "- The relationship between the independent variable (X) and the dependent variable (Y) must be linear.\n",
        "\n",
        "- This means the change in Y is proportional to the change in X.\n",
        "\n",
        "- Mathematically:\n",
        "\n",
        "    E(Yâˆ£X)=Î²0â€‹+Î²1â€‹X\n",
        "    \n",
        "- Check: Use a scatter plot of X vs. Y or residual plots â€” the points should form a roughly straight-line pattern.\n",
        "\n",
        "2. Independence of Errors\n",
        "\n",
        "- The residuals (errors) should be independent of each other.\n",
        "\n",
        "- No autocorrelation should exist (especially important in time series data).\n",
        "\n",
        "- Violation Example: If one error term influences the next, such as in time-dependent data.\n",
        "\n",
        "- Check: Use the Durbin-Watson test for autocorrelation.\n",
        "\n",
        "3. Homoscedasticity (Constant Variance of Errors)\n",
        "\n",
        "- The variance of residuals should be constant across all levels of X.\n",
        "\n",
        "- That is, the spread of errors should not increase or decrease with X.\n",
        "\n",
        "- Violation (Heteroscedasticity): When residuals spread wider or narrower as X changes.\n",
        "\n",
        "- Check: Plot residuals vs. fitted values â€” they should form a random scatter with constant spread.\n",
        "\n",
        "4. Normality of Errors\n",
        "\n",
        "- The residuals (Îµ) should be normally distributed with a mean of 0.\n",
        "\n",
        "- This assumption is crucial for valid hypothesis testing and confidence intervals.\n",
        "\n",
        "- Check: Use a histogram, Q-Q plot, or the Shapiroâ€“Wilk test for normality.\n",
        "\n",
        "5. No Perfect Multicollinearity\n",
        "\n",
        "- Since SLR involves only one independent variable, this assumption mainly applies to Multiple Linear Regression.\n",
        "\n",
        "- However, in SLR, it ensures that X is not constant (i.e., there is some variation in X).\n",
        "\n",
        "6. No Measurement Error in X\n",
        "\n",
        "- The independent variable (X) should be measured accurately.\n",
        "\n",
        "- Errors in measuring X can bias the estimated slope and intercept.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PC2JB9D1CGCR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 3: Write the mathematical equation for a simple linear regression model and explain each term.**\n",
        "\n",
        "The mathematical equation for a Simple Linear Regression (SLR) model is:\n",
        "\n",
        "      Y=Î²0â€‹+Î²1â€‹X+Îµ\n",
        "\n",
        "ðŸ”¹ Explanation of Each Term\n",
        "\n",
        "| **Symbol**         | **Term**                                  | **Meaning / Description**                                                                                                                                           |\n",
        "| ------------------ | ----------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Y**              | Dependent Variable (Response Variable)    | The variable we want to **predict or explain** (e.g., sales, marks, price).                                                                                         |\n",
        "| **X**              | Independent Variable (Predictor Variable) | The variable used to **predict Y** (e.g., advertising budget, study hours).                                                                                         |\n",
        "| **Î²â‚€ (Beta Zero)** | Intercept                                 | The **expected value of Y when X = 0**. It represents where the regression line crosses the Y-axis.                                                                 |\n",
        "| **Î²â‚ (Beta One)**  | Slope Coefficient                         | The **change in Y** for a **one-unit change in X**, keeping other factors constant. It shows the **strength and direction** of the relationship.                    |\n",
        "| **Îµ (Epsilon)**    | Error Term (Residual)                     | Represents the **difference between the observed value (actual Y)** and the **predicted value (Å¶)**. It captures random noise or factors not included in the model. |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "otg31CkkCF-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 4: Provide a real-world example where simple linear regression can be applied.**\n",
        "\n",
        "A real-world example of applying Simple Linear Regression (SLR) is in predicting a studentâ€™s exam score based on study hours.\n",
        "\n",
        "Example: Predicting Exam Scores from Study Hours\n",
        "\n",
        "- Scenario\n",
        "\n",
        "  - A teacher wants to find out how the number of hours students study (X) affects their exam scores (Y).\n",
        "  - She collects data from several students:\n",
        "\n",
        "  | **Study Hours (X)** | **Exam Score (Y)** |\n",
        "  | ------------------- | ------------------ |\n",
        "  | 1                   | 42                 |\n",
        "  | 2                   | 50                 |\n",
        "  | 3                   | 58                 |\n",
        "  | 4                   | 70                 |\n",
        "  | 5                   | 78                 |\n",
        "\n",
        "- Applying Simple Linear Regression\n",
        "\n",
        "  - Using regression analysis, the teacher finds the relationship:\n",
        "\n",
        "    Y^=35+8X\n",
        "\n",
        "- Interpretation\n",
        "\n",
        "  - Intercept (35): A student who doesnâ€™t study at all (0 hours) is expected to score 35 marks.\n",
        "\n",
        "  - Slope (8): For each additional hour of study, the studentâ€™s exam score increases by 8 marks on average.\n",
        "\n",
        "- Use of the Model\n",
        "\n",
        "  - If a student studies 6 hours, the predicted score is:\n",
        "\n",
        "    Y^=35+8(6)=83\n",
        "\n",
        "    So, the model predicts that a student who studies 6 hours will score approximately 83 marks.\n",
        "\n",
        "- Purpose and Insights\n",
        "\n",
        "   - Helps predict future exam scores.\n",
        "\n",
        "  - Shows a positive linear relationship between study time and performance.\n",
        "\n",
        "  - Allows the teacher to advise students on how much study time may improve   their scores.    \n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "E6B8hUeHCF3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 5: What is the method of least squares in linear regression?**\n",
        "\n",
        "The method of least squares is a mathematical technique used in linear regression to find the best-fitting line through a set of data points by minimizing the sum of the squared differences between the observed values and the predicted values.\n",
        "\n",
        "- Concept\n",
        "\n",
        "In Simple Linear Regression, the relationship between the dependent variable (Y) and independent variable (X) is modeled as:\n",
        "\n",
        "    ð‘Œ=ð›½0+ð›½1ð‘‹+ðœ€\n",
        "\n",
        "    \n",
        "\n",
        "The goal is to find estimates of Î²â‚€ (intercept) and Î²â‚ (slope) such that the fitted line:\n",
        "\n",
        "    ð‘Œ^=ð‘0+ð‘1ð‘‹\n",
        "\n",
        "\n",
        "best represents the data â€” meaning the differences between actual and predicted values (called residuals) are as small as possible.\n",
        "\n",
        "- Residuals\n",
        "\n",
        "For each observation i:\n",
        "\n",
        "    ð‘’ð‘–=ð‘Œð‘–âˆ’ð‘Œ^ð‘–\n",
        "\tâ€‹\n",
        "where:\n",
        "\n",
        "ð‘Œð‘–= actual observed value\n",
        "\n",
        "ð‘Œ^ð‘– = predicted value from the regression line\n",
        "\n",
        "Least Squares Principle\n",
        "\n",
        "The method of least squares minimizes the sum of squared residuals (SSR):\n",
        "\n",
        "    ð‘†ð‘†ð‘…=âˆ‘(ð‘Œð‘–âˆ’ð‘Œ^ð‘–)^2   (n=0, n=-1)\n",
        "\n",
        "By minimizing SSR, we find the best-fit line that makes the overall error (difference between data points and the line) as small as possible.\n",
        "\n",
        "-  Interpretation\n",
        "\n",
        "   - The line obtained through least squares ensures that the sum of squared errors is minimal.\n",
        "\n",
        "   - It provides the best linear unbiased estimator (BLUE) under classical regression assumptions."
      ],
      "metadata": {
        "id": "WyMEue9HG0Am"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 6: What is Logistic Regression? How does it differ from Linear Regression?**\n",
        "\n",
        "ANS-- Logistic Regression â€” Definition\n",
        "\n",
        "Logistic Regression is a statistical method used to model the relationship between one or more independent variables (predictors) and a categorical dependent variable, most commonly binary (having two possible outcomes, e.g., yes/no, pass/fail, disease/no disease).\n",
        "\n",
        "Instead of predicting a continuous value like linear regression, logistic regression predicts the probability that an observation belongs to a particular class\n",
        "\n",
        "| **Feature**                | **Linear Regression**                     | **Logistic Regression**                            |\n",
        "| -------------------------- | ----------------------------------------- | -------------------------------------------------- |\n",
        "| **Purpose**                | Predicts **continuous values**            | Predicts **categorical outcomes (probabilities)**  |\n",
        "| **Dependent Variable (Y)** | Continuous (e.g., marks, price, salary)   | Binary or categorical (e.g., pass/fail, yes/no)    |\n",
        "| **Equation Form**          | ( Y = Î²_0 + Î²_1X + Îµ )                    | ( \\ln\\left(\\frac{p}{1-p}\\right) = Î²_0 + Î²_1X )     |\n",
        "| **Output Range**           | Can take any real number                  | Confined between **0 and 1**                       |\n",
        "| **Model Type**             | **Regression (prediction)**               | **Classification (probability estimation)**        |\n",
        "| **Curve Shape**            | Straight line                             | S-shaped **sigmoid curve**                         |\n",
        "| **Error Function**         | Minimizes **Sum of Squared Errors (SSE)** | Maximizes **Likelihood Function (MLE)**            |\n",
        "| **Assumptions**            | Requires linearity between X and Y        | Requires linearity between X and **log-odds** of Y |\n"
      ],
      "metadata": {
        "id": "lsW72H2jGz87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q- 7 Name and briefly describe three common evaluation metrics for regression models.**\n",
        "\n",
        "1. Mean Absolute Error (MAE)\n",
        "\n",
        "- Definition:\n",
        "  - MAE measures the average absolute difference between the actual and predicted values.\n",
        "  - It tells us how far, on average, the predictions are from the true values.\n",
        "\n",
        "- Interpretation:\n",
        "\n",
        "  - Lower MAE â†’ better model performance.\n",
        "\n",
        "  - It gives an idea of the average prediction error in the same units as the output variable.\n",
        "\n",
        "- Example:\n",
        "  - If MAE = 3.5, it means predictions are off by 3.5 units on average.\n",
        "\n",
        "2. Mean Squared Error (MSE)\n",
        "\n",
        "- Definition:\n",
        "  \n",
        "   MSE calculates the average of the squared differences between the actual and predicted values.\n",
        "\n",
        "- Interpretation:\n",
        "\n",
        "   - Squaring penalizes larger errors more heavily than smaller ones.\n",
        "\n",
        "   - Useful when large prediction errors are particularly undesirable.\n",
        "\n",
        "   - Lower MSE indicates better model accuracy.\n",
        "\n",
        "    Note: Since errors are squared, the unit of MSE is the square of the output unit (e.g., if Y is in â‚¹, MSE is in â‚¹Â²).\n",
        "\n",
        "3. R-squared (Coefficient of Determination)\n",
        "\n",
        "- Definition:\n",
        "\n",
        "RÂ² measures how well the regression line fits the data â€” i.e., the proportion of variance in the dependent variable explained by the independent variable(s).\n",
        "\n",
        "\n",
        "\n",
        "- Interpretation:\n",
        "\n",
        "  - RÂ² ranges from 0 to 1.\n",
        "\n",
        "  - RÂ² = 1 â†’ Perfect fit (all points lie exactly on the regression line).\n",
        "\n",
        "  - RÂ² = 0 â†’ Model explains none of the variance in Y.\n",
        "\n",
        "  - Higher RÂ² means the model explains more of the data variability."
      ],
      "metadata": {
        "id": "3nfTTVUrY2O9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Q-8 What is the purpose of the R-squared metric in regression analysis?**\n",
        "\n",
        " **Purpose of the R-squared Metric in Regression Analysis**\n",
        "\n",
        "The **R-squared (RÂ²)** â€” also known as the **coefficient of determination** â€” is a key statistical measure used to **evaluate the goodness of fit** of a regression model.\n",
        "\n",
        "In simple terms, it tells us **how well the independent variable(s) explain the variability** in the dependent variable.\n",
        "\n",
        "\n",
        "- **Definition**\n",
        "\n",
        "    R-squared is defined as:\n",
        "\n",
        "    [R^2 = 1 - \\frac{SS_{res}}{SS_{tot}}]\n",
        "\n",
        "   Where:\n",
        "\n",
        "     * ( SS_{res} = \\sum (Y_i - \\hat{Y}_i)^2 ) â†’ Residual Sum of Squares (unexplained variance)\n",
        "     * ( SS_{tot} = \\sum (Y_i - \\bar{Y})^2 ) â†’ Total Sum of Squares (total variance in Y)\n",
        "\n",
        "\n",
        "- **Interpretation**\n",
        "   * **RÂ² = 0** â†’ The model explains **none** of the variability in Y (very poor fit).\n",
        "   * **RÂ² = 1** â†’ The model explains **all** the variability in Y (perfect fit).\n",
        "   * **RÂ² between 0 and 1** â†’ Indicates the **proportion of variance explained** by the model.\n",
        "\n",
        "    Example:\n",
        "    \n",
        "    If **RÂ² = 0.85**, it means **85% of the variation** in the dependent variable (Y) is explained by the independent variable(s), while **15%** remains unexplained due to other factors or random error.\n",
        "\n",
        "\n",
        "\n",
        "- **Purpose of R-squared**\n",
        "\n",
        "1. **Measure of Goodness of Fit:**\n",
        "   RÂ² tells how well the regression line fits the actual data points.\n",
        "\n",
        "2. **Explains Predictive Power:**\n",
        "   It indicates how much of the change in Y can be predicted from X.\n",
        "   Higher RÂ² â†’ better predictive accuracy.\n",
        "\n",
        "3. **Model Comparison:**\n",
        "   RÂ² can be used to **compare multiple models** â€” higher RÂ² usually suggests a better-fitting model (though not always the most appropriate one).\n",
        "\n",
        "4. **Quantifies Explained Variance:**\n",
        "   It provides a clear numeric value for how much of the variation in the dependent variable is accounted for by the independent variable(s).\n",
        "\n",
        "\n",
        "- **Limitations**\n",
        "\n",
        "    * **Does not indicate causation** â€” a high RÂ² does not mean X causes Y.\n",
        "    * **Can be misleading in multiple regression**, as adding more predictors always increases RÂ² (even if they are irrelevant).\n",
        "    * **Adjusted RÂ²** is preferred in such cases since it penalizes unnecessary variables.\n",
        "\n"
      ],
      "metadata": {
        "id": "6s1IsL7OY2Lh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 9: Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept.**\n",
        "(Include your Python code and output in the code box below.)"
      ],
      "metadata": {
        "id": "OiEe5xN6Y2IV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eID3xZOuAeGR",
        "outputId": "2b9aa0f1-ddc9-42c0-8a65-b76e61a706f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Slope (Coefficient): 0.6\n",
            "Intercept: 2.2\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Example data\n",
        "# X = independent variable (reshaped into 2D array for sklearn)\n",
        "# y = dependent variable\n",
        "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# Create and fit the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Print the slope (coefficient) and intercept\n",
        "print(\"Slope (Coefficient):\", model.coef_[0])\n",
        "print(\"Intercept:\", model.intercept_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Question 10: How do you interpret the coefficients in a simple linear regression model?**\n",
        "\n",
        "\n",
        "\n",
        "In a **simple linear regression model**, the goal is to describe the relationship between one **independent variable (X)** and one **dependent variable (Y)**.\n",
        "\n",
        "The model is written as:\n",
        "[\n",
        "Y = \\beta_0 + \\beta_1X + \\varepsilon\n",
        "]\n",
        "where:\n",
        "\n",
        "* ( Y ): dependent (response) variable\n",
        "* ( X ): independent (predictor) variable\n",
        "* ( \\beta_0 ): intercept\n",
        "* ( \\beta_1 ): slope (coefficient of ( X ))\n",
        "* ( \\varepsilon ): error term\n",
        "\n",
        " Interpretation of the coefficients:\n",
        "\n",
        "1. **Intercept (( \\beta_0 ))**\n",
        "\n",
        "   * It represents the **predicted value of ( Y )** when ( X = 0 ).\n",
        "   * In other words, itâ€™s the baseline value of ( Y ) when there is no influence from ( X ).\n",
        "   *  *Note:* If ( X = 0 ) is outside the data range, the intercept may not have a meaningful interpretation.\n",
        "\n",
        "   **Example:**\n",
        "   If the regression equation is ( \\text{Sales} = 50 + 10 \\times \\text{Advertising} ),\n",
        "   then when advertising = 0, predicted sales = 50 units.\n",
        "\n",
        "2. **Slope (( \\beta_1 ))**\n",
        "\n",
        "   * It indicates the **average change in ( Y )** for a **one-unit increase in ( X )**.\n",
        "   * The **sign** of ( \\beta_1 ) shows the **direction** of the relationship:\n",
        "\n",
        "     * ( \\beta_1 > 0 ): positive relationship (as ( X ) increases, ( Y ) increases)\n",
        "     * ( \\beta_1 < 0 ): negative relationship (as ( X ) increases, ( Y ) decreases)\n",
        "\n",
        "   **Example:**\n",
        "   In the equation ( \\text{Sales} = 50 + 10 \\times \\text{Advertising} ):\n",
        "   For every 1 unit increase in advertising spending, sales increase by 10 units (on average).\n",
        "\n",
        "- Summary Table:\n",
        "\n",
        "| Coefficient | Symbol      | Interpretation                                  |\n",
        "| ----------- | ----------- | ----------------------------------------------- |\n",
        "| Intercept   | ( \\beta_0 ) | Expected value of ( Y ) when ( X = 0 )          |\n",
        "| Slope       | ( \\beta_1 ) | Change in ( Y ) for each 1-unit change in ( X ) |\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "PUfM-P1qcfEW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jNofKoa4cEvX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}